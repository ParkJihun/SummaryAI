import os
import streamlit as st
import azure.cognitiveservices.speech as speechsdk
import openai
import ffmpeg
from datetime import datetime
from pydub import AudioSegment

# Streamlit UI
st.title("ğŸ“¢ ìŒì„± íŒŒì¼ í…ìŠ¤íŠ¸ ë³€í™˜ ë° ìš”ì•½ê¸°")

# ğŸ“Œ FFmpeg ìë™ ì„¤ì¹˜ (Streamlit Cloud í™˜ê²½)
if not os.path.exists("ffmpeg"):
    os.system("apt-get install ffmpeg -y")

# ğŸ“Œ FFmpeg ì‹¤í–‰ ê²½ë¡œ ì„¤ì •
AudioSegment.converter = "ffmpeg"

# ğŸ“Œ Azure Speech to Text API ì„¤ì •
speech_key = "116aa0968d984023b92eaae4d952c0a6"
service_region = "koreacentral"

# ğŸ“Œ íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸµ ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["m4a", "wav"])
if uploaded_file is not None:
    input_audio_path = f"temp_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav"
    
    # ğŸ“Œ ì—…ë¡œë“œí•œ íŒŒì¼ì„ FFmpegë¡œ ë³€í™˜ (16kHz PCM WAV)
    converted_audio_path = "converted_audio.wav"
    
    with open(input_audio_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.write("ğŸµ ìŒì„± íŒŒì¼ì„ 16kHz WAVë¡œ ë³€í™˜ ì¤‘...")
    
    try:
        audio = AudioSegment.from_file(input_audio_path)
        audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)  # 16kHz, ëª¨ë…¸, 16bit PCM
        audio.export(converted_audio_path, format="wav")
        st.success("âœ… ë³€í™˜ ì™„ë£Œ!")
    except Exception as e:
        st.error(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì‹¤íŒ¨: {e}")
        st.stop()

    # ğŸ“Œ Azure Speech-to-Text ì²˜ë¦¬
    st.write("ğŸ™ï¸ ìŒì„± ì¸ì‹ ì¤‘...")
    
    # Azure ì„¤ì •
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    speech_config.speech_recognition_language = "ko-KR"
    audio_config = speechsdk.audio.AudioConfig(filename=converted_audio_path)
    speech_recognizer = speechsdk.SpeechRecognizer(speech_config, audio_config)

    results = []
    def handle_final_result(evt):
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
            results.append(evt.result.text)

    speech_recognizer.recognized.connect(handle_final_result)
    speech_recognizer.start_continuous_recognition()

    import time
    time.sleep(10)  # ì¸ì‹ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
    speech_recognizer.stop_continuous_recognition()

    # ğŸ“Œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ í‘œì‹œ
    full_text = " ".join(results)
    st.subheader("ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸")
    st.write(full_text)

    # ğŸ“Œ ChatGPT ìš”ì•½
    openai.api_key = "YOUR_OPENAI_API_KEY"
    
    def summarize_text(text):
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ìŒì„± ë‚´ìš©ì„ ì§§ê³  ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”."},
                {"role": "user", "content": text}
            ]
        )
        return response["choices"][0]["message"]["content"]

    summarized_text = summarize_text(full_text)
    st.subheader("ğŸ“Œ ìš”ì•½ ê²°ê³¼")
    st.write(summarized_text)

    # ğŸ“Œ ìš”ì•½ëœ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
    summary_file_path = "summary.txt"
    with open(summary_file_path, "w", encoding="utf-8") as f:
        f.write(summarized_text)

    st.download_button("â¬‡ï¸ ìš”ì•½ëœ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ", open(summary_file_path, "rb"), file_name="summary.txt")
